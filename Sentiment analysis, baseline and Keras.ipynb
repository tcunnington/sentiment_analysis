{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_vectors_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "Proof of concept data: Data is sentences from reviews on Yelp, IMDB, and Amazon. All sentences are labelled positive or negative--there's meant to be no neutral sentences in the data. Sentiment is binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/sentiment_sentences/'\n",
    "file_names = ['amazon_cells_labelled.txt','imdb_labelled.txt','yelp_labelled.txt']\n",
    "\n",
    "def read_data(file_name):\n",
    "    return pd.read_csv(os.path.join(data_dir, file_name), sep='\\t', header=None, quoting=csv.QUOTE_NONE)\\\n",
    "        .rename(columns={\n",
    "            0: 'sentence',\n",
    "            1: 'score',\n",
    "        })\n",
    "review_sentences = pd.concat([read_data(f) for f in file_names]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So there is no way for me to plug it in here in the US unless I go by a converter.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sentences.head(1)['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data set is small and we have to split to train. May not be enough to get good results. Lets find out how many words per sentence on avg..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22641"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothing = pd.read_csv('data/Womens Clothing E-Commerce Reviews.csv', index_col=0)\n",
    "clothing = clothing[['Review Text', 'Rating']].dropna()\n",
    "len(clothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put data in a specific structure in case I change sources later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentiment is binary\n",
    "df = pd.DataFrame(columns=['text','score'])\n",
    "\n",
    "# df['text'] = review_sentences['sentence']\n",
    "# df['score'] = review_sentences['score']\n",
    "\n",
    "\n",
    "df['text'] = clothing['Review Text']\n",
    "df['score'] = clothing['Rating'] >= 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean, remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>True</td>\n",
       "      <td>absolutely wonderful silky and sexy and comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>True</td>\n",
       "      <td>love this dress it s sooo pretty i happened to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>False</td>\n",
       "      <td>i had such high hopes for this dress and reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>True</td>\n",
       "      <td>i love love love this jumpsuit it s fun flirty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>True</td>\n",
       "      <td>this shirt is very flattering to all due to th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  score  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...   True   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...   True   \n",
       "2  I had such high hopes for this dress and reall...  False   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...   True   \n",
       "4  This shirt is very flattering to all due to th...   True   \n",
       "\n",
       "                                               clean  \n",
       "0  absolutely wonderful silky and sexy and comfor...  \n",
       "1  love this dress it s sooo pretty i happened to...  \n",
       "2  i had such high hopes for this dress and reall...  \n",
       "3  i love love love this jumpsuit it s fun flirty...  \n",
       "4  this shirt is very flattering to all due to th...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.parsing.preprocessing import strip_numeric, strip_punctuation, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "# prep_filters = [strip_punctuation, strip_numeric, strip_multiple_whitespaces]\n",
    "prep_filters = [strip_punctuation, strip_multiple_whitespaces]\n",
    "\n",
    "df['clean'] = df['text'].map(lambda s: ' '.join(preprocess_string(s.lower(), prep_filters)))\n",
    "# ' '.join(preprocess_string(df.head(1)['sentence'][0], prep_filters))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create word to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in df['clean']]\n",
    "dct = Dictionary(corpus)\n",
    "\n",
    "dct.filter_extremes(no_below=5)\n",
    "dct.compactify()\n",
    "\n",
    "vocab_size = len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exclude words that don't exist so we don't have to think about how to embed them :)\n",
    "def sent2seq(sent, dct): \n",
    "    return [idx for idx in dct.doc2idx(sent.split()) if idx != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 3, 2, 1]\n",
      "[24, 14, 34, 36, 33, 17, 15, 37, 25, 16, 13, 8, 28, 41, 18, 31, 30, 8, 34, 32, 11, 32, 7, 5, 6, 24, 22, 29, 26, 19, 20, 23, 10, 21, 41, 12, 9, 38, 27, 29, 35, 40, 39, 32]\n",
      "[53, 78, 55, 56, 51, 14, 70, 86, 89, 51, 26, 58, 31, 32, 75, 64, 84, 74, 52, 9, 75, 76, 75, 48, 79, 45, 66, 90, 83, 71, 32, 63, 88, 87, 20, 67, 69, 81, 54, 87, 1, 49, 65, 42, 54, 53, 85, 80, 82, 60, 72, 77, 44, 68, 61, 57, 62, 46, 50, 87, 68, 60, 73, 47, 59, 91, 43]\n",
      "[24, 24, 24, 99, 34, 96, 95, 94, 93, 101, 102, 97, 100, 98, 92]\n",
      "[113, 85, 108, 104, 107, 103, 109, 115, 112, 22, 102, 117, 110, 114, 76, 111, 116, 117, 105, 106, 24, 113]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    sample_sentence = df['clean'][i]\n",
    "    seq = sent2seq(sample_sentence, dct)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['seqlen'] = [len(sent2seq(s, dct)) for s in df['clean']]\n",
    "df['is_valid_seq_gensim'] = df['seqlen'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43.30586104854026, 42.0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['seqlen'].mean(), df['seqlen'].median(), (~df['is_valid_seq_gensim']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A typical sequence is about 9 words. Is this large? It seems like it may be too small given the limited number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections \n",
    "DataDTO = collections.namedtuple('DataDTO',['x_train','y_train','l_train','x_test','y_test','l_test']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OUTPUT_SIZE = 2\n",
    "PAD_SIZE = 40 # 99th percentile (longer ones truncated)\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad(xs, pad_size=PAD_SIZE): # pass in as list, since next dim is not fixed size\n",
    "    padded = np.zeros([len(xs), pad_size])\n",
    "    lens = np.zeros(len(xs), dtype=np.int32)\n",
    "    for i,vec in enumerate(xs): # by row\n",
    "        if len(vec) > pad_size:\n",
    "            vec = vec[:pad_size]\n",
    "        \n",
    "        padded[i,:len(vec)] = vec\n",
    "        lens[i] = len(vec)\n",
    "        \n",
    "    return padded, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22641, 40) (22641,) (22641,)\n"
     ]
    }
   ],
   "source": [
    "data_name = 'gensim indexes'\n",
    "\n",
    "data, lengths = pad([sent2seq(s,dct) for s in df[df['is_valid_seq_gensim']]['clean']])\n",
    "y_labels = np.array(df[df['is_valid_seq_gensim']]['score'])\n",
    "\n",
    "print(data.shape, lengths.shape, y_labels.shape)\n",
    "\n",
    "# do test train split\n",
    "split_idxs = np.random.random(len(data)) < 0.9\n",
    "\n",
    "x_train = data[split_idxs]\n",
    "y_train = y_labels[split_idxs]\n",
    "lengths_train = lengths[split_idxs]\n",
    "\n",
    "x_test = data[~split_idxs]\n",
    "y_test = y_labels[~split_idxs]\n",
    "lengths_test = lengths[~split_idxs]\n",
    "\n",
    "data_gensim_dct = DataDTO(x_train, y_train, lengths_train, x_test, y_test, lengths_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: bag of words model with LR or NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl_msk = np.random.rand(len(df)) < 0.8\n",
    "bl_train_x, bl_train_y = df[bl_msk]['clean'], df[bl_msk]['score']\n",
    "bl_test_x, bl_test_y   = df[~bl_msk]['clean'], df[~bl_msk]['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.54      0.66      1092\n",
      "        True       0.87      0.97      0.92      3480\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      4572\n",
      "   macro avg       0.87      0.75      0.79      4572\n",
      "weighted avg       0.87      0.87      0.86      4572\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8694225721784777"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_lemma(text):\n",
    "    return [w.lemma_ for w in nlp(text)]\n",
    "\n",
    "pipe = Pipeline([('tfidf', CountVectorizer(ngram_range=(1,2), tokenizer=tokenize_lemma)),\n",
    "                 ('classifier', MultinomialNB())])\n",
    "\n",
    "pipe.fit(bl_train_x, bl_train_y)\n",
    "bl_pred = pipe.predict(bl_test_x)\n",
    "print(classification_report(bl_test_y, bl_pred))\n",
    "accuracy_score(bl_test_y, bl_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since these reviews are relatively \"long\" (longer than a single sentence or a few words) these classic methods can give a pretty commendable performance. We will not really try to beat them by a high margin, but will simply try to match this performance while building a good, generalizable neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Try \n",
    "    - RMSProp, AdaGrad\n",
    "    - tune learning rate\n",
    "    - additional regularization\n",
    "    - softsign activation function\n",
    "    - Xavier weight initialization\n",
    "    - more data: larger dataset, semi-supervised learning, or construct new training examples by rearranging sentences (currently have more params than training examples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional\n",
    "from keras.layers import SpatialDropout1D, Dropout, Conv1D, AveragePooling1D\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, split=' ')\n",
    "tokenizer.fit_on_texts(df['clean'])\n",
    "X = tokenizer.texts_to_sequences(df['clean'])\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, df['score'], test_size = 0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 118, 10)           49440     \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 118, 10)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 40)                4960      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 54,482\n",
      "Trainable params: 54,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_size = 10\n",
    "rnn_size = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, \n",
    "                    input_length = X.shape[1], embeddings_initializer='glorot_normal'))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "# model.add(Conv1D(2*embedding_size, kernel_size = 3))\n",
    "# model.add(Conv1D(2*embedding_size, kernel_size = 3))\n",
    "# model.add(AveragePooling1D(4))\n",
    "model.add(Bidirectional(LSTM(rnn_size, dropout=0.5, recurrent_dropout=0.3)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(rnn_size//2, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15848 samples, validate on 6793 samples\n",
      "Epoch 1/5\n",
      "78s - loss: 0.4782 - acc: 0.7899 - val_loss: 0.3543 - val_acc: 0.8422\n",
      "Epoch 2/5\n",
      "70s - loss: 0.3550 - acc: 0.8479 - val_loss: 0.3182 - val_acc: 0.8578\n",
      "Epoch 3/5\n",
      "62s - loss: 0.3227 - acc: 0.8646 - val_loss: 0.3056 - val_acc: 0.8659\n",
      "Epoch 4/5\n",
      "65s - loss: 0.3059 - acc: 0.8728 - val_loss: 0.3023 - val_acc: 0.8769\n",
      "Epoch 5/5\n",
      "62s - loss: 0.2959 - acc: 0.8756 - val_loss: 0.3069 - val_acc: 0.8699\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_history = model.fit(x_train, to_categorical(y_train), \n",
    "                          batch_size=batch_size, epochs=5,\n",
    "                          validation_data=(x_test, to_categorical(y_test)),\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We are managing to match baseline model performance quite quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score,acc = model.evaluate(x_test, to_categorical(y_test), batch_size=batch_size, verbose=2)\n",
    "# score,acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = train_history.history['loss']\n",
    "val_loss = train_history.history['val_loss']\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LSTM's overfit quite easily unfortunately. \n",
    "\n",
    "> TODO: Implement early stopping, tweak other regularizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
