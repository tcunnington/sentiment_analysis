{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import gensim\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_vars():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_vectors_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "Data is sentences from reviews on Yelp, IMDB, and Amazon. All sentences are labelled positive or negative--there's meant to be no neutral sentences in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/sentiment_sentences/'\n",
    "file_names = ['amazon_cells_labelled.txt','imdb_labelled.txt','yelp_labelled.txt']\n",
    "\n",
    "def read_data(file_name):\n",
    "    return pd.read_csv(os.path.join(data_dir, file_name), sep='\\t', header=None, quoting=csv.QUOTE_NONE)\\\n",
    "        .rename(columns={\n",
    "            0: 'sentence',\n",
    "            1: 'score',\n",
    "        })\n",
    "df = pd.concat([read_data(f) for f in file_names]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So there is no way for me to plug it in here in the US unless I go by a converter.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)['sentence'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean, remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>good case excellent value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>great for the jawbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>the mic is great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score  \\\n",
       "0  So there is no way for me to plug it in here i...      0   \n",
       "1                        Good case, Excellent value.      1   \n",
       "2                             Great for the jawbone.      1   \n",
       "3  Tied to charger for conversations lasting more...      0   \n",
       "4                                  The mic is great.      1   \n",
       "\n",
       "                                               clean  \n",
       "0  so there is no way for me to plug it in here i...  \n",
       "1                          good case excellent value  \n",
       "2                              great for the jawbone  \n",
       "3  tied to charger for conversations lasting more...  \n",
       "4                                   the mic is great  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import strip_numeric, strip_punctuation, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "# prep_filters = [strip_punctuation, strip_numeric, strip_multiple_whitespaces]\n",
    "prep_filters = [strip_punctuation, strip_multiple_whitespaces]\n",
    "\n",
    "df['clean'] = df['sentence'].map(lambda s: ' '.join(preprocess_string(s.lower(), prep_filters)))\n",
    "# ' '.join(preprocess_string(df.head(1)['sentence'][0], prep_filters))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: bag of words model with LR, NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with learned word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create word to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "corpus = [sent.split() for sent in df['clean']]\n",
    "dct = Dictionary(corpus)\n",
    "\n",
    "dct.filter_extremes(no_below=5)\n",
    "dct.compactify()\n",
    "\n",
    "vocab_size = len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exclude words that don't exist so we don't have to think about how to embed them :)\n",
    "def sent2seq(sent): \n",
    "    return [idx for idx in dct.doc2idx(sent.split()) if idx != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seqlen'] = [len(sent2seq(s)) for s in df['clean']]\n",
    "df = df[df['seqlen'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 14, 7, 10, 18, 2, 9, 15, 11, 8, 6, 4, 6, 13, 17, 16, 5, 3, 1, 0]\n",
      "[21, 19, 20, 22]\n",
      "[23, 2, 13]\n",
      "[15, 24, 2, 26, 28, 25, 27]\n",
      "[13, 7, 23]\n",
      "[5, 31, 15, 13, 11, 15, 30, 8, 15, 32, 34, 33, 15, 30, 29, 35]\n",
      "[38, 45, 31, 42, 41, 42, 44, 13, 37, 39, 36, 39, 43, 40, 1, 40]\n",
      "[38, 45, 46, 49, 48, 45, 47, 31, 50]\n",
      "[15, 53, 5, 54, 52, 51]\n",
      "[58, 0, 57, 39, 51, 55, 56]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sample_sentence = df['clean'][i]\n",
    "    seq = sent2seq(sample_sentence)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INPUT_SIZE = 300\n",
    "# OUTPUT_SIZE = 2\n",
    "PAD_SIZE = 40 # 99th percentile (longer ones truncated)\n",
    "BATCH_SIZE = 10\n",
    "LSTM_SIZE = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2993, 40), (2993,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pad(xs, pad_size=PAD_SIZE): # pass in as list, since next dim is not fixed size\n",
    "    padded = np.zeros([len(xs), pad_size])\n",
    "    lens = np.zeros(len(xs), dtype=np.int32)\n",
    "    for i,vec in enumerate(xs): # by row\n",
    "        if len(vec) > pad_size:\n",
    "            vec = vec[:pad_size]\n",
    "        \n",
    "        padded[i,:len(vec)] = vec\n",
    "        lens[i] = len(vec)\n",
    "        \n",
    "    return padded, lens\n",
    "\n",
    "data, lengths = pad([sent2seq(s) for s in df['clean']])\n",
    "data.shape, lengths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = np.array(df['score'])\n",
    "# y_labels = np.array([np.array([1-s,s]) for s in df['score']])\n",
    "\n",
    "# do test train split\n",
    "split_idxs = np.random.random(len(df)) < 0.8\n",
    "\n",
    "x_train = data[split_idxs]\n",
    "y_train = y_labels[split_idxs]\n",
    "lengths_train = lengths[split_idxs]\n",
    "\n",
    "x_test = data[~split_idxs]\n",
    "y_test = y_labels[~split_idxs]\n",
    "lengths_test = lengths[~split_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(batch_size=BATCH_SIZE, \n",
    "               lstm_size=LSTM_SIZE, \n",
    "               embedding_size=64):\n",
    "\n",
    "    reset_tf()\n",
    "\n",
    "    x = tf.placeholder(tf.int32, shape=(batch_size, PAD_SIZE), name='x') # as indices of embedding\n",
    "    seqlens = tf.placeholder(tf.int32, shape=[batch_size], name='seqlens')\n",
    "    y_true = tf.placeholder(tf.float32, shape=[batch_size], name='y_true')\n",
    "\n",
    "    # Start with embedding layer\n",
    "    embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0))\n",
    "    # embeddings = tf.get_variable('embeddings', [vocab_size, embedding_size])\n",
    "    embedding_input = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "    # RNN - try also BasicRNNCell, GRUCell, BasicLSTMCell\n",
    "    lstm = tf.contrib.rnn.GRUCell(lstm_size)\n",
    "    lstm_init_state = lstm.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    # Iteratively compute output of recurrent network\n",
    "    rnn_out, lstm_state = tf.nn.dynamic_rnn(lstm, embedding_input, initial_state=lstm_init_state,\n",
    "                                            sequence_length=seqlens, dtype=tf.float32)\n",
    "\n",
    "    rnn_out = tf.nn.dropout(rnn_out, 0.9)\n",
    "\n",
    "    # Get single output accoring to each sequence length\n",
    "    out = tf.gather_nd(rnn_out, tf.stack([tf.range(batch_size), seqlens-1], axis=1))\n",
    "\n",
    "    # Linear activation (FC layer on top of the LSTM net)\n",
    "    y = tf.layers.dense(out, 1, activation=None)\n",
    "    y = tf.reshape(y,(batch_size,))\n",
    "    \n",
    "    return x, seqlens, y, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "x, seqlens, y, y_true = build_lstm(lstm_size=48)\n",
    "\n",
    "preds = tf.nn.softmax(y)\n",
    "label_predictions = preds > 0.5\n",
    "correct = tf.equal(tf.cast(label_predictions, tf.int32), tf.cast(y_true, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "ETA = 0.01\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=y_true))\n",
    "optimizer = tf.train.AdamOptimizer(ETA).minimize(loss) \n",
    "# optimizer = tf.train.RMSPropOptimizer(ETA).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(epoch 0)\t Train: 0.49298, 0.51271 \tTest: 0.42506, 0.55556\n",
      "(epoch 1)\t Train: 0.25656, 0.56441 \tTest: 0.38735, 0.58730\n",
      "(epoch 2)\t Train: 0.13795, 0.56949 \tTest: 0.42265, 0.60000\n",
      "(epoch 3)\t Train: 0.07666, 0.57119 \tTest: 0.54989, 0.58730\n",
      "(epoch 4)\t Train: 0.05818, 0.57797 \tTest: 0.55915, 0.59048\n",
      "(epoch 5)\t Train: 0.03893, 0.58093 \tTest: 0.68873, 0.58571\n",
      "(epoch 6)\t Train: 0.02980, 0.58390 \tTest: 0.75989, 0.59841\n",
      "(epoch 7)\t Train: 0.02909, 0.58771 \tTest: 0.65924, 0.58889\n",
      "(epoch 8)\t Train: 0.03809, 0.58390 \tTest: 0.68514, 0.58413\n",
      "(epoch 9)\t Train: 0.04102, 0.58220 \tTest: 0.69925, 0.58571\n",
      "(epoch 10)\t Train: 0.03802, 0.58602 \tTest: 0.80177, 0.58730\n",
      "(epoch 11)\t Train: 0.02526, 0.58729 \tTest: 0.78708, 0.58095\n",
      "(epoch 12)\t Train: 0.04061, 0.58686 \tTest: 0.81123, 0.58254\n",
      "(epoch 13)\t Train: 0.05178, 0.58559 \tTest: 0.73437, 0.58889\n",
      "(epoch 14)\t Train: 0.03231, 0.58771 \tTest: 0.82247, 0.58889\n",
      "(epoch 15)\t Train: 0.02942, 0.58347 \tTest: 0.87045, 0.58889\n",
      "(epoch 16)\t Train: 0.02062, 0.58559 \tTest: 0.93426, 0.59048\n",
      "(epoch 17)\t Train: 0.01216, 0.58941 \tTest: 1.12451, 0.59524\n",
      "(epoch 18)\t Train: 0.01255, 0.58771 \tTest: 1.22898, 0.58889\n",
      "(epoch 19)\t Train: 0.01158, 0.58983 \tTest: 1.19887, 0.58095\n",
      "(epoch 20)\t Train: 0.01915, 0.58983 \tTest: 1.16061, 0.58571\n",
      "(epoch 21)\t Train: 0.03375, 0.58983 \tTest: 1.13483, 0.59365\n",
      "(epoch 22)\t Train: 0.04262, 0.59110 \tTest: 1.12187, 0.59206\n",
      "(epoch 23)\t Train: 0.05346, 0.58814 \tTest: 0.94745, 0.59365\n",
      "(epoch 24)\t Train: 0.04669, 0.58644 \tTest: 0.94791, 0.59683\n",
      "(epoch 25)\t Train: 0.03301, 0.58856 \tTest: 0.96049, 0.59048\n",
      "(epoch 26)\t Train: 0.02911, 0.58686 \tTest: 1.03756, 0.58730\n",
      "(epoch 27)\t Train: 0.04133, 0.58729 \tTest: 0.98922, 0.59365\n",
      "(epoch 28)\t Train: 0.03631, 0.58983 \tTest: 1.13923, 0.59048\n",
      "(epoch 29)\t Train: 0.03922, 0.58941 \tTest: 1.08030, 0.58571\n"
     ]
    }
   ],
   "source": [
    "reset_vars()\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "metrics = {\n",
    "    'train_loss': [],\n",
    "    'train_acc': [],\n",
    "    'test_loss': [],\n",
    "    'test_acc' : [],\n",
    "}\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    shuffle_idxs = np.arange(len(x_train))\n",
    "    np.random.shuffle(shuffle_idxs)\n",
    "\n",
    "    x_train = x_train[shuffle_idxs]\n",
    "    y_train = y_train[shuffle_idxs]\n",
    "    lengths_train = lengths_train[shuffle_idxs]\n",
    "    \n",
    "    metrics['train_loss'].append(0)\n",
    "    metrics['train_acc'].append(0)\n",
    "    \n",
    "    num_steps = len(x_train) // batch_size\n",
    "#     print(i, metrics['train_loss'][i])\n",
    "\n",
    "    # loop through train data in batches\n",
    "    for j in range(num_steps):\n",
    "\n",
    "        start, end = j*batch_size, (j+1)*batch_size\n",
    "#         print(x_train[start:end])\n",
    "#         print(y_train[start:end])\n",
    "#         print(lengths_train[start:end])\n",
    "#         continue\n",
    "        train_feed = {\n",
    "            x: x_train[start:end],\n",
    "            y_true: y_train[start:end],\n",
    "            seqlens: lengths_train[start:end],\n",
    "        }\n",
    "\n",
    "        sess.run(optimizer, feed_dict=train_feed)\n",
    "        l, a = sess.run([loss, accuracy], feed_dict=train_feed)\n",
    "        metrics['train_loss'][i] += l\n",
    "        metrics['train_acc'][i] += a\n",
    "\n",
    "    # calculate train metrics\n",
    "    metrics['train_loss'][i] /= num_steps\n",
    "    metrics['train_acc'][i] /= num_steps\n",
    "    \n",
    "    # prep test loop\n",
    "    num_test_steps = len(x_test) // batch_size     # TODO this leaves out the last few data points..\n",
    "    metrics['test_loss'].append(0)\n",
    "    metrics['test_acc'].append(0)\n",
    "    \n",
    "    for k in range(num_test_steps):\n",
    "        start, end = k*batch_size, (k+1)*batch_size\n",
    "        tl, ta = sess.run([loss, accuracy], feed_dict={\n",
    "            x: x_test[start:end],\n",
    "            y_true: y_test[start:end],\n",
    "            seqlens: lengths_test[start:end]\n",
    "        })\n",
    "        metrics['test_loss'][i] += tl\n",
    "        metrics['test_acc'][i] += ta\n",
    "        \n",
    "    metrics['test_loss'][i] /= num_test_steps\n",
    "    metrics['test_acc'][i] /= num_test_steps\n",
    "    \n",
    "    # print\n",
    "    print(\"(epoch %i)\\t Train: %0.5f, %0.5f \\tTest: %0.5f, %0.5f\" % (i, metrics['train_loss'][i], metrics['train_acc'][i], metrics['test_loss'][i], metrics['test_acc'][i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Spacy's GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load all embeddings into memory? Sure why not, dataset is small\n",
    "glove = np.zeros([len(dct), 300])\n",
    "for i, word in dct.items():\n",
    "    glove[i,:] = nlp.vocab['word'].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph is nearly the same except for the embedding layer. It is no longer learned, but constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
