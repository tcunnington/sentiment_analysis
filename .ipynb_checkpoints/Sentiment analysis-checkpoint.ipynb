{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import gensim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = None\n",
    "\n",
    "def reset_vars():\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "def reset_tf():\n",
    "    global sess\n",
    "    if sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_vectors_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "Proof of concept data: Data is sentences from reviews on Yelp, IMDB, and Amazon. All sentences are labelled positive or negative--there's meant to be no neutral sentences in the data. Sentiment is binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'data/sentiment_sentences/'\n",
    "file_names = ['amazon_cells_labelled.txt','imdb_labelled.txt','yelp_labelled.txt']\n",
    "\n",
    "def read_data(file_name):\n",
    "    return pd.read_csv(os.path.join(data_dir, file_name), sep='\\t', header=None, quoting=csv.QUOTE_NONE)\\\n",
    "        .rename(columns={\n",
    "            0: 'sentence',\n",
    "            1: 'score',\n",
    "        })\n",
    "review_sentences = pd.concat([read_data(f) for f in file_names]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  score\n",
       "0  So there is no way for me to plug it in here i...      0\n",
       "1                        Good case, Excellent value.      1\n",
       "2                             Great for the jawbone.      1\n",
       "3  Tied to charger for conversations lasting more...      0\n",
       "4                                  The mic is great.      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So there is no way for me to plug it in here in the US unless I go by a converter.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_sentences.head(1)['sentence'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data set is small and we have to split to train. May not be enough to get good results. Lets find out how many words per sentence on avg..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put data in a specific structure in case I change sources later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment is binary\n",
    "df = pd.DataFrame(columns=['text','is_pos'])\n",
    "\n",
    "df['text'] = review_sentences['sentence']\n",
    "df['is_pos'] = review_sentences['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean, remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_pos</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>so there is no way for me to plug it in here i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>good case excellent value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "      <td>great for the jawbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "      <td>tied to charger for conversations lasting more...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>the mic is great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_pos  \\\n",
       "0  So there is no way for me to plug it in here i...       0   \n",
       "1                        Good case, Excellent value.       1   \n",
       "2                             Great for the jawbone.       1   \n",
       "3  Tied to charger for conversations lasting more...       0   \n",
       "4                                  The mic is great.       1   \n",
       "\n",
       "                                               clean  \n",
       "0  so there is no way for me to plug it in here i...  \n",
       "1                          good case excellent value  \n",
       "2                              great for the jawbone  \n",
       "3  tied to charger for conversations lasting more...  \n",
       "4                                   the mic is great  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.parsing.preprocessing import strip_numeric, strip_punctuation, strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "# prep_filters = [strip_punctuation, strip_numeric, strip_multiple_whitespaces]\n",
    "prep_filters = [strip_punctuation, strip_multiple_whitespaces]\n",
    "\n",
    "df['clean'] = df['text'].map(lambda s: ' '.join(preprocess_string(s.lower(), prep_filters)))\n",
    "# ' '.join(preprocess_string(df.head(1)['sentence'][0], prep_filters))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create word to index mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in df['clean']]\n",
    "dct = Dictionary(corpus)\n",
    "\n",
    "dct.filter_extremes(no_below=5)\n",
    "dct.compactify()\n",
    "\n",
    "vocab_size = len(dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exclude words that don't exist so we don't have to think about how to embed them :)\n",
    "def sent2seq(sent, dct): \n",
    "    return [idx for idx in dct.doc2idx(sent.split()) if idx != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 14, 7, 10, 18, 2, 9, 15, 11, 8, 6, 4, 6, 13, 17, 16, 5, 3, 1, 0]\n",
      "[21, 19, 20, 22]\n",
      "[23, 2, 13]\n",
      "[15, 24, 2, 26, 28, 25, 27]\n",
      "[13, 7, 23]\n",
      "[5, 31, 15, 13, 11, 15, 30, 8, 15, 32, 34, 33, 15, 30, 29, 35]\n",
      "[38, 45, 31, 42, 41, 42, 44, 13, 37, 39, 36, 39, 43, 40, 1, 40]\n",
      "[38, 45, 46, 49, 48, 45, 47, 31, 50]\n",
      "[15, 53, 5, 54, 52, 51]\n",
      "[58, 0, 57, 39, 51, 55, 56]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sample_sentence = df['clean'][i]\n",
    "    seq = sent2seq(sample_sentence, dct)\n",
    "    print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['seqlen'] = [len(sent2seq(s, dct)) for s in df['clean']]\n",
    "df['is_valid_seq_gensim'] = df['seqlen'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.934, 9.0, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['seqlen'].mean(), df['seqlen'].median(), (~df['is_valid_seq_gensim']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A typical sequence is about 9 words. Is this large? It seems like it may be too small given the limited number of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# OUTPUT_SIZE = 2\n",
    "PAD_SIZE = 40 # 99th percentile (longer ones truncated)\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pad(xs, pad_size=PAD_SIZE): # pass in as list, since next dim is not fixed size\n",
    "    padded = np.zeros([len(xs), pad_size])\n",
    "    lens = np.zeros(len(xs), dtype=np.int32)\n",
    "    for i,vec in enumerate(xs): # by row\n",
    "        if len(vec) > pad_size:\n",
    "            vec = vec[:pad_size]\n",
    "        \n",
    "        padded[i,:len(vec)] = vec\n",
    "        lens[i] = len(vec)\n",
    "        \n",
    "    return padded, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2993, 40) (2993,) (2993,)\n"
     ]
    }
   ],
   "source": [
    "data_name = 'gensim indexes'\n",
    "\n",
    "data, lengths = pad([sent2seq(s,dct) for s in df[df['is_valid_seq_gensim']]['clean']])\n",
    "y_labels = np.array(df[df['is_valid_seq_gensim']]['score_is_'])\n",
    "\n",
    "print(data.shape, lengths.shape, y_labels.shape)\n",
    "\n",
    "# do test train split\n",
    "split_idxs = np.random.random(len(data)) < 0.8\n",
    "\n",
    "x_train = data[split_idxs]\n",
    "y_train = y_labels[split_idxs]\n",
    "lengths_train = lengths[split_idxs]\n",
    "\n",
    "x_test = data[~split_idxs]\n",
    "y_test = y_labels[~split_idxs]\n",
    "lengths_test = lengths[~split_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Baseline: bag of words model with LR or NB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bl_msk = np.random.rand(len(df)) < 0.8\n",
    "bl_train = df[bl_msk]['text'], df[bl_msk]['score']\n",
    "bl_test = df[~bl_msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_lemma(text):\n",
    "    return [w.lemma_ for w in nlp(text)]\n",
    "\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize_lemma)),\n",
    "                 ('classifier', MultinomialNB())])\n",
    "\n",
    "\n",
    "pipe.fit(bl_train, train_res)\n",
    "pipe.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with learned word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Graph runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def run_graph(x, seqlens, y_true, optimizer, loss, accuracy, num_epochs=20, feed_extra={}):\n",
    "\n",
    "    # TODO do not use global vars!\n",
    "    global data_name\n",
    "    global x_train, y_train\n",
    "    global x_test, y_test\n",
    "    global lengths_train, lengths_test\n",
    "    \n",
    "    print('Using global data! - ' + data_name)\n",
    "    \n",
    "    reset_vars()\n",
    "\n",
    "    metrics = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'test_loss': [],\n",
    "        'test_acc' : [],\n",
    "    }\n",
    "    print_every = num_epochs // 10\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "\n",
    "        shuffle_idxs = np.arange(len(x_train))\n",
    "        np.random.shuffle(shuffle_idxs)\n",
    "\n",
    "        x_train = x_train[shuffle_idxs]\n",
    "        y_train = y_train[shuffle_idxs]\n",
    "        lengths_train = lengths_train[shuffle_idxs]\n",
    "\n",
    "        metrics['train_loss'].append(0)\n",
    "        metrics['train_acc'].append(0)\n",
    "\n",
    "        num_steps = len(x_train) // batch_size\n",
    "\n",
    "        # loop through train data in batches\n",
    "        for j in range(num_steps):\n",
    "\n",
    "            start, end = j*batch_size, (j+1)*batch_size\n",
    "\n",
    "            train_feed = {\n",
    "                x: x_train[start:end],\n",
    "                y_true: y_train[start:end],\n",
    "                seqlens: lengths_train[start:end],\n",
    "            }\n",
    "            train_feed.update(feed_extra)\n",
    "            \n",
    "            sess.run(optimizer, feed_dict=train_feed)\n",
    "            l, a = sess.run([loss, accuracy], feed_dict=train_feed)\n",
    "            metrics['train_loss'][i] += l\n",
    "            metrics['train_acc'][i] += a\n",
    "\n",
    "        # calculate train metrics\n",
    "        metrics['train_loss'][i] /= num_steps\n",
    "        metrics['train_acc'][i] /= num_steps\n",
    "\n",
    "        # prep test loop\n",
    "        num_test_steps = len(x_test) // batch_size     # TODO this leaves out the last few data points..\n",
    "        metrics['test_loss'].append(0)\n",
    "        metrics['test_acc'].append(0)\n",
    "\n",
    "        for k in range(num_test_steps):\n",
    "            start, end = k*batch_size, (k+1)*batch_size\n",
    "            \n",
    "            test_feed = {\n",
    "                x: x_test[start:end],\n",
    "                y_true: y_test[start:end],\n",
    "                seqlens: lengths_test[start:end]\n",
    "            }\n",
    "            test_feed.update(feed_extra)\n",
    "            \n",
    "            tl, ta = sess.run([loss, accuracy], feed_dict=test_feed)\n",
    "            metrics['test_loss'][i] += tl\n",
    "            metrics['test_acc'][i] += ta\n",
    "\n",
    "        metrics['test_loss'][i] /= num_test_steps\n",
    "        metrics['test_acc'][i] /= num_test_steps\n",
    "\n",
    "#         print(i, i % print_every, print_every, num_epochs)\n",
    "        if i % print_every == 0 or i == (num_epochs - 1):\n",
    "            print(\"(epoch %i)\\t Train: %0.5f, %0.5f \\tTest: %0.5f, %0.5f\" % (i, metrics['train_loss'][i], metrics['train_acc'][i], metrics['test_loss'][i], metrics['test_acc'][i]))\n",
    "        \n",
    "    return metrics\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(batch_size=10, \n",
    "                rnn_size=25, \n",
    "                embedding_size=64,\n",
    "                dropout_keepprob=0.8):\n",
    "\n",
    "    reset_tf()\n",
    "\n",
    "    x = tf.placeholder(tf.int32, shape=(batch_size, PAD_SIZE), name='x') # as indices of embedding\n",
    "    seqlens = tf.placeholder(tf.int32, shape=[batch_size], name='seqlens')\n",
    "    y_true = tf.placeholder(tf.float32, shape=[batch_size], name='y_true')\n",
    "\n",
    "    # Start with embedding layer\n",
    "    embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0))\n",
    "    embedding_input = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "    # RNN - try also BasicRNNCell, GRUCell, BasicLSTMCell\n",
    "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "\n",
    "    # Iteratively compute output of recurrent network\n",
    "    rnn_out, lstm_state = tf.nn.dynamic_rnn(rnn_cell, embedding_input,\n",
    "                                            sequence_length=seqlens, dtype=tf.float32)\n",
    "\n",
    "    rnn_out = tf.nn.dropout(rnn_out, dropout_keepprob)\n",
    "\n",
    "    # Get single output accoring to each sequence length\n",
    "    out = tf.gather_nd(rnn_out, tf.stack([tf.range(batch_size), seqlens-1], axis=1))\n",
    "\n",
    "    # Linear activation (FC layer on top of the LSTM net)\n",
    "    y = tf.layers.dense(out, 1, activation=None)\n",
    "    y = tf.reshape(y,(batch_size,))\n",
    "    \n",
    "    return x, seqlens, y, y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build it, create metrics, run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "x, seqlens, y, y_true = build_graph(rnn_size=12, embedding_size=10, dropout_keepprob=0.7)\n",
    "\n",
    "preds = tf.nn.softmax(y)\n",
    "label_predictions = preds > 0.5\n",
    "correct = tf.equal(tf.cast(label_predictions, tf.int32), tf.cast(y_true, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "ETA = 0.01\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=y_true))\n",
    "optimizer = tf.train.AdamOptimizer(ETA).minimize(loss) \n",
    "# optimizer = tf.train.RMSPropOptimizer(ETA).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global data! - gensim indexes\n",
      "(epoch 0)\t Train: 0.61926, 0.50583 \tTest: 0.47772, 0.53448\n",
      "(epoch 2)\t Train: 0.29001, 0.56917 \tTest: 0.39771, 0.58276\n",
      "(epoch 4)\t Train: 0.18953, 0.57500 \tTest: 0.41030, 0.58966\n",
      "(epoch 6)\t Train: 0.12863, 0.58417 \tTest: 0.50852, 0.58793\n",
      "(epoch 8)\t Train: 0.10683, 0.58708 \tTest: 0.70245, 0.57931\n",
      "(epoch 10)\t Train: 0.07898, 0.58958 \tTest: 0.64053, 0.59483\n",
      "(epoch 12)\t Train: 0.05972, 0.59167 \tTest: 0.84004, 0.59655\n",
      "(epoch 14)\t Train: 0.05464, 0.59167 \tTest: 0.98393, 0.59138\n",
      "(epoch 16)\t Train: 0.06037, 0.59417 \tTest: 0.89994, 0.59483\n",
      "(epoch 18)\t Train: 0.04476, 0.59458 \tTest: 1.00614, 0.59483\n",
      "(epoch 19)\t Train: 0.06138, 0.59167 \tTest: 0.97537, 0.58966\n"
     ]
    }
   ],
   "source": [
    "run_metrics = run_graph(x, seqlens, y_true, optimizer, loss, accuracy, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Better than chance, but likely the model is hindered by the small amount of training data and the sparsity of words--after all the embedding has no way to use context and thus won't build very meaningful relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM with Spacy's GloVe word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1969033628702164"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of embedding matrix, Gb\n",
    "nlp.vocab.vectors.data.nbytes / 1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# exclude words that don't have a vector for now\n",
    "def sent2seq_glove(sent,nlp): \n",
    "    return [nlp.vocab[w].rank for w in sent.split() if nlp.vocab[w].has_vector]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rebuild data using spacy's indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['seqlen_glove'] = [len(sent2seq_glove(s,nlp)) for s in df['clean']]\n",
    "df['is_valid_seq_glove'] = df['seqlen_glove'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 40) (3000,) (3000,)\n"
     ]
    }
   ],
   "source": [
    "data_name = 'spacy indexes'\n",
    "\n",
    "data, lengths = pad([sent2seq_glove(s,nlp) for s in df[df['is_valid_seq_glove']]['clean']])\n",
    "y_labels = np.array(df[df['is_valid_seq_glove']]['is_pos'])\n",
    "\n",
    "print(data.shape, lengths.shape, y_labels.shape)\n",
    "\n",
    "# do test train split\n",
    "split_idxs = np.random.random(len(df)) < 0.8\n",
    "\n",
    "x_train = data[split_idxs]\n",
    "y_train = y_labels[split_idxs]\n",
    "lengths_train = lengths[split_idxs]\n",
    "\n",
    "x_test = data[~split_idxs]\n",
    "y_test = y_labels[~split_idxs]\n",
    "lengths_test = lengths[~split_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12.088333333333333, 10.0, 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['seqlen_glove'].mean(), df['seqlen_glove'].median(), (~df['is_valid_seq_glove']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fortunately this embedding is able to capture more words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph is nearly the exact same except for the embedding layer. It is no longer learned, but constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT_SIZE = 300\n",
    "\n",
    "def build_graph_glove(batch_size=10, \n",
    "                     rnn_size=25,\n",
    "                     dropout_keepprob=0.8):\n",
    "\n",
    "    reset_tf()\n",
    "\n",
    "    x = tf.placeholder(tf.int32, shape=(batch_size, PAD_SIZE), name='x') # as indices of embedding\n",
    "    seqlens = tf.placeholder(tf.int32, shape=[batch_size], name='seqlens')\n",
    "    y_true = tf.placeholder(tf.float32, shape=[batch_size], name='y_true')\n",
    "\n",
    "    # Start with embedding layer\n",
    "    embedding_matrix = tf.placeholder(shape=nlp.vocab.vectors.data.shape, \n",
    "                                      dtype=tf.float32, name='embedding_matrix')\n",
    "    rnn_input = tf.nn.embedding_lookup(embedding_matrix, x)\n",
    "    \n",
    "    # optional dense layer...\n",
    "#     rnn_input = tf.layers.dense(embedding_input, 64, activation=tf.nn.elu)\n",
    "\n",
    "    # RNN - try also BasicRNNCell, GRUCell, BasicLSTMCell\n",
    "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "\n",
    "    # Iteratively compute output of recurrent network\n",
    "    rnn_out, lstm_state = tf.nn.dynamic_rnn(rnn_cell, rnn_input, \n",
    "                                            sequence_length=seqlens, dtype=tf.float32)\n",
    "\n",
    "    rnn_out = tf.nn.dropout(rnn_out, dropout_keepprob)\n",
    "\n",
    "    # Get single output accoring to each sequence length\n",
    "    out = tf.gather_nd(rnn_out, tf.stack([tf.range(batch_size), seqlens-1], axis=1))\n",
    "\n",
    "    # Linear activation (FC layer on top of the LSTM net)\n",
    "    y = tf.layers.dense(out, 1, activation=None)\n",
    "    y = tf.reshape(y,(batch_size,))\n",
    "    \n",
    "    return x, seqlens, y, y_true, embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, seqlens, y, y_true, embedding_matrix = build_graph_glove(rnn_size=12, dropout_keepprob=0.7) #batch_size=\n",
    "\n",
    "preds = tf.nn.softmax(y)\n",
    "label_predictions = preds > 0.5\n",
    "correct = tf.equal(tf.cast(label_predictions, tf.int32), tf.cast(y_true, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "ETA = 0.01\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=y_true))\n",
    "optimizer = tf.train.AdamOptimizer(ETA).minimize(loss) \n",
    "# optimizer = tf.train.RMSPropOptimizer(ETA).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global data! - spacy indexes\n",
      "(epoch 0)\t Train: 0.38731, 0.54042 \tTest: 0.36386, 0.55500\n",
      "(epoch 2)\t Train: 0.17819, 0.57333 \tTest: 0.31417, 0.58000\n",
      "(epoch 4)\t Train: 0.11398, 0.58458 \tTest: 0.40807, 0.56833\n",
      "(epoch 6)\t Train: 0.07632, 0.58667 \tTest: 0.42323, 0.58000\n",
      "(epoch 8)\t Train: 0.08202, 0.59083 \tTest: 0.45657, 0.57500\n",
      "(epoch 10)\t Train: 0.04012, 0.59167 \tTest: 0.55716, 0.58000\n",
      "(epoch 12)\t Train: 0.04930, 0.59583 \tTest: 0.54478, 0.59000\n",
      "(epoch 14)\t Train: 0.04080, 0.59375 \tTest: 0.57848, 0.57667\n",
      "(epoch 16)\t Train: 0.02015, 0.59167 \tTest: 0.59988, 0.58167\n",
      "(epoch 18)\t Train: 0.02084, 0.59500 \tTest: 0.73319, 0.57333\n",
      "(epoch 19)\t Train: 0.04593, 0.59667 \tTest: 0.53993, 0.58667\n"
     ]
    }
   ],
   "source": [
    "run_metrics = run_graph(x, seqlens, y_true, optimizer, loss, accuracy, num_epochs=20, \n",
    "                        feed_extra={embedding_matrix:nlp.vocab.vectors.data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> No great improvement (but at least it's not eating massive amount of memory now!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# INPUT_SIZE = 300\n",
    "\n",
    "def build_graph_bidir(batch_size=10, \n",
    "                      rnn_size=25, \n",
    "                      embedding_size=64,\n",
    "                      dropout_keepprob=0.8):\n",
    "\n",
    "    reset_tf()\n",
    "\n",
    "    x = tf.placeholder(tf.int32, shape=(batch_size, PAD_SIZE), name='x') # as indices of embedding\n",
    "    seqlens = tf.placeholder(tf.int32, shape=[batch_size], name='seqlens')\n",
    "    y_true = tf.placeholder(tf.float32, shape=[batch_size], name='y_true')\n",
    "\n",
    "#     # Start with embedding layer\n",
    "#     embeddings = tf.Variable(nlp.vocab.vectors.data, trainable=False)\n",
    "#     embedding_input = tf.nn.embedding_lookup(embeddings, x)\n",
    "    # Start with embedding layer\n",
    "    embeddings = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0))\n",
    "    embedding_input = tf.nn.embedding_lookup(embeddings, x)\n",
    "\n",
    "    # RNN - try also BasicRNNCell, GRUCell, BasicLSTMCell\n",
    "    rnn_fw = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    rnn_bw = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "\n",
    "    rnn_outs, rnn_states  = tf.nn.bidirectional_dynamic_rnn(\n",
    "                                cell_fw=rnn_fw,\n",
    "                                cell_bw=rnn_bw,\n",
    "                                inputs=embedding_input,\n",
    "                                sequence_length=seqlens, dtype=tf.float32)\n",
    " \n",
    "    out_fw, out_bw = rnn_outs\n",
    "    state_fw, state_bw = rnn_states\n",
    "    \n",
    "    out_fw = tf.gather_nd(out_fw, tf.stack([tf.range(batch_size), seqlens-1], axis=1))\n",
    "    out_bw = tf.gather_nd(out_bw, tf.stack([tf.range(batch_size), seqlens-1], axis=1))\n",
    "    \n",
    "#     print(out_fw)\n",
    "    rnn_out = tf.concat([out_fw, out_bw], axis=1)\n",
    "#     print(rnn_out)\n",
    "    \n",
    "    out = tf.nn.dropout(rnn_out, dropout_keepprob)    \n",
    "\n",
    "    # Linear activation (FC layer on top of the LSTM net)\n",
    "    y = tf.layers.dense(out, 1, activation=None)\n",
    "    y = tf.reshape(y,(batch_size,))\n",
    "    \n",
    "    return x, seqlens, y, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:430: calling reverse_sequence (from tensorflow.python.ops.array_ops) with seq_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "seq_dim is deprecated, use seq_axis instead\n",
      "WARNING:tensorflow:From /Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:454: calling reverse_sequence (from tensorflow.python.ops.array_ops) with batch_dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "batch_dim is deprecated, use batch_axis instead\n"
     ]
    }
   ],
   "source": [
    "x, seqlens, y, y_true = build_graph_bidir(rnn_size=8, embedding_size=10, dropout_keepprob=0.7) #batch_size=\n",
    "\n",
    "preds = tf.nn.softmax(y)\n",
    "label_predictions = preds > 0.5\n",
    "correct = tf.equal(tf.cast(label_predictions, tf.int32), tf.cast(y_true, tf.int32))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "ETA = 0.01\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y, labels=y_true))\n",
    "optimizer = tf.train.AdamOptimizer(ETA).minimize(loss) \n",
    "# optimizer = tf.train.RMSPropOptimizer(ETA).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global data! - spacy indexes\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[1,1] = 353329 is not in [0, 863)\n\t [[Node: embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_x_0_1, embedding_lookup/axis)]]\n\nCaused by op 'embedding_lookup', defined at:\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-bc7af7d734f8>\", line 1, in <module>\n    x, seqlens, y, y_true = build_graph_bidir(rnn_size=8, embedding_size=10, dropout_keepprob=0.7) #batch_size=\n  File \"<ipython-input-31-130724e15eb7>\", line 19, in build_graph_bidir\n    embedding_input = tf.nn.embedding_lookup(embeddings, x)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 310, in embedding_lookup\n    transform_fn=None)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2659, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3142, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1,1] = 353329 is not in [0, 863)\n\t [[Node: embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_x_0_1, embedding_lookup/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1,1] = 353329 is not in [0, 863)\n\t [[Node: embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_x_0_1, embedding_lookup/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-648bf39a1238>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseqlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-ebfe8576f035>\u001b[0m in \u001b[0;36mrun_graph\u001b[0;34m(x, seqlens, y_true, optimizer, loss, accuracy, num_epochs, feed_extra)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mtrain_feed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_extra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_feed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1,1] = 353329 is not in [0, 863)\n\t [[Node: embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_x_0_1, embedding_lookup/axis)]]\n\nCaused by op 'embedding_lookup', defined at:\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-bc7af7d734f8>\", line 1, in <module>\n    x, seqlens, y, y_true = build_graph_bidir(rnn_size=8, embedding_size=10, dropout_keepprob=0.7) #batch_size=\n  File \"<ipython-input-31-130724e15eb7>\", line 19, in build_graph_bidir\n    embedding_input = tf.nn.embedding_lookup(embeddings, x)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 310, in embedding_lookup\n    transform_fn=None)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/embedding_ops.py\", line 133, in _embedding_lookup_and_transform\n    result = _clip(array_ops.gather(params[0], ids, name=name),\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 2659, in gather\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3142, in gather_v2\n    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/Users/Taylor/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1,1] = 353329 is not in [0, 863)\n\t [[Node: embedding_lookup = GatherV2[Taxis=DT_INT32, Tindices=DT_INT32, Tparams=DT_FLOAT, _class=[\"loc:@Adam/Assign_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Variable/read, _arg_x_0_1, embedding_lookup/axis)]]\n"
     ]
    }
   ],
   "source": [
    "run_metrics = run_graph(x, seqlens, y_true, optimizer, loss, accuracy, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A little improvment over a single LSTM here, but once I move on to longer text it may begin to make a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
